import os
from dotenv import load_dotenv
from supabase import create_client, Client

# .env íŒŒì¼ ë¡œë“œ (ë¡œì»¬ ê°œë°œ í™˜ê²½ìš©)
load_dotenv()

# Supabase ì„¤ì • (ê¶Œí•œ ë¬¸ì œë¥¼ í”¼í•˜ê¸° ìœ„í•´ Service Role Keyì¸ 'Secret_keys'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤)
url = os.getenv("Project_URL", "").strip()
key = os.getenv("Secret_keys", "").strip()

if not url:
    raise ValueError("âŒ Project_URL environment variable is missing or empty.")
if not key:
    raise ValueError("âŒ Secret_keys environment variable is missing or empty. (RLS ìš°íšŒë¥¼ ìœ„í•´ Service Role Keyê°€ í•„ìš”í•©ë‹ˆë‹¤)")

# Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„± (Secret Keyë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  í…Œì´ë¸”ì— ëŒ€í•œ CRUD ê¶Œí•œì„ í™•ë³´)
try:
    supabase: Client = create_client(url, key)
except Exception as e:
    raise RuntimeError(f"âŒ Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")


import pandas as pd
from datetime import datetime, timedelta

def load_toss_data_from_supabase():
    """
    Supabaseì—ì„œ ê°€ì¥ ìµœê·¼ ìˆ˜ì§‘ëœ ë‚ ì§œì˜ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ DataFrameìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    (ë°ì´í„°í”„ë ˆì„ê³¼ ë°ì´í„°ì˜ ì‹¤ì œ ìˆ˜ì§‘ ì‹œê°(collected_at)ì„ í•¨ê»˜ ë°˜í™˜)
    """
    try:
        # 1. ê°€ì¥ ìµœê·¼ ìˆ˜ì§‘ëœ ë‚ ì§œ í™•ì¸
        res = supabase.table("toss_yg_score_stk") \
            .select("collected_at") \
            .order("collected_at", desc=True) \
            .limit(1) \
            .execute()

        if not res.data:
            print("ğŸš¨ Supabaseì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None, None

        latest_timestamp = res.data[0]['collected_at']
        # 'T' ë˜ëŠ” ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ë‚ ì§œ ë¶€ë¶„ë§Œ ì¶”ì¶œ (Timestamp ëŒ€ì‘)
        target_date = latest_timestamp.replace('T', ' ').split(' ')[0]
        print(f"ğŸ“… ê°€ì¥ ìµœê·¼ ë°ì´í„° ë‚ ì§œ: {target_date} (ë°ì´í„° ë¡œë“œ ì¤‘...)")

        # í•´ë‹¹ ë‚ ì§œì˜ ë°ì´í„° ë²”ìœ„ ì„¤ì • (UTC ê¸°ì¤€ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ í•˜ë£¨ë¥¼ í¬í•¨)
        start_date = target_date
        end_date_dt = datetime.strptime(target_date, "%Y-%m-%d") + timedelta(days=1)
        end_date = end_date_dt.strftime("%Y-%m-%d")

        # 2. í•´ë‹¹ ë‚ ì§œ ë°ì´í„° ì¿¼ë¦¬ (í˜ì´ì§€ë„¤ì´ì…˜ ì ìš©)
        all_data = []
        limit = 1000
        offset = 0
        
        print(f"â³ ë°ì´í„° ë¡œë“œ ì¤‘ (Range: {start_date} ~ {end_date})...", end='', flush=True)

        while True:
            response = supabase.table("toss_yg_score_stk") \
                .select("*") \
                .gte("collected_at", start_date) \
                .lt("collected_at", end_date) \
                .range(offset, offset + limit - 1) \
                .execute()

            if not response.data:
                break
            
            all_data.extend(response.data)
            
            if len(response.data) < limit:
                break
                
            offset += limit
            print(".", end='', flush=True)
            
        print(f"\nâœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ì´ {len(all_data)}ê±´")

        if not all_data:
            print(f"ğŸš¨ {target_date} ë‚ ì§œì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return None, None

        df = pd.DataFrame(all_data)
        
        # ì‹¤ì œ ë°ì´í„° ì¤‘ ê°€ì¥ ìµœì‹  ìˆ˜ì§‘ ì‹œê° ì¶”ì¶œ
        actual_latest_at = df['collected_at'].max()

        # 3. ë°ì´í„° ì „ì²˜ë¦¬
        # ë§¤ìˆ˜(buy)ëŠ” ì–‘ìˆ˜, ë§¤ë„(sell)ëŠ” ìŒìˆ˜ë¡œ ë³€í™˜
        df['final_amount'] = df.apply(lambda x: x['amount'] if x['ranking_type'] == 'buy' else -x['amount'], axis=1)

        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ ë° ì´ë¦„ ë³€ê²½
        df_processed = df[['investor', 'stock_name', 'stock_code', 'final_amount', 'collected_at']].copy()
        
        # ì¤‘ë³µ ì œê±°: ë™ì¼ íˆ¬ìì, ì¢…ëª©, ë§¤ë§¤íƒ€ì…ì— ëŒ€í•´ ê°€ì¥ ë§ˆì§€ë§‰ì— ìˆ˜ì§‘ëœ ë°ì´í„°ë§Œ ì‚¬ìš©
        # (ì‹¤ì‹œê°„ í¬ë¡¤ë§ì´ ëˆ„ì ë  ê²½ìš° ìµœì‹  ìŠ¤ëƒ…ìƒ·ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•¨)
        df_dedup = df.sort_values(by=['investor', 'stock_code', 'stock_name', 'collected_at']) \
            .drop_duplicates(subset=['investor', 'stock_code', 'stock_name', 'ranking_type'], keep='last')

        # ë§¤ìˆ˜/ë§¤ë„ í•©ì‚° (ê°™ì€ ì¢…ëª©ì— ëŒ€í•´ ë§¤ìˆ˜/ë§¤ë„ ëª¨ë‘ ìˆì„ ìˆ˜ ìˆìŒ)
        df_total = df_dedup.groupby(['investor', 'stock_name', 'stock_code'], as_index=False)['final_amount'].sum()
        
        # ì»¬ëŸ¼ëª… ë§¤í•‘ (ê¸°ì¡´ ë¡œì§ê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´)
        df_total.rename(columns={
            'investor': 'íˆ¬ìì', 
            'stock_name': 'ì¢…ëª©ëª…', 
            'stock_code': 'ì¢…ëª©ì½”ë“œ', 
            'final_amount': 'ê¸ˆì•¡'
        }, inplace=True)

        print(f"âœ… Supabase ë°ì´í„° ë¡œë“œ ë° í†µí•© ì™„ë£Œ: {len(df_total)}ê±´ (ê¸°ì¤€ì‹œê°: {actual_latest_at})")
        return df_total, actual_latest_at

    except Exception as e:
        print(f"ğŸš¨ Supabase ë°ì´í„° ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        return None, None

    except Exception as e:
        print(f"ğŸš¨ Supabase ë°ì´í„° ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        return None

def load_etf_pdf_from_supabase():
    """
    Supabaseì˜ etf_pdf í…Œì´ë¸”ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ DataFrameìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    ë¡œì»¬ì— etf_pdf_snapshot.csv íŒŒì¼ì´ ìˆìœ¼ë©´ ìš°ì„ ì ìœ¼ë¡œ ì½ì–´ì˜µë‹ˆë‹¤.
    """
    try:
        # 0. ë¡œì»¬ CSV ìŠ¤ëƒ…ìƒ· í™•ì¸ (ì‚¬ìš© ì•ˆ í•¨)
        # csv_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'etf_pdf_snapshot.csv')
        # if os.path.exists(csv_path):
        #     try:
        #         df_pdf = pd.read_csv(csv_path)
        #         # ì¢…ëª©ì½”ë“œ í¬ë§·íŒ… (6ìë¦¬ ë¬¸ìì—´)
        #         if 'ETFì¢…ëª©ì½”ë“œ' in df_pdf.columns:
        #             df_pdf['ETFì¢…ëª©ì½”ë“œ'] = df_pdf['ETFì¢…ëª©ì½”ë“œ'].astype(str).str.zfill(6)
        #         if 'êµ¬ì„±ì¢…ëª©ì½”ë“œ' in df_pdf.columns:
        #             df_pdf['êµ¬ì„±ì¢…ëª©ì½”ë“œ'] = df_pdf['êµ¬ì„±ì¢…ëª©ì½”ë“œ'].astype(str).str.zfill(6)
        #         print(f"âœ… ë¡œì»¬ CSV ìŠ¤ëƒ…ìƒ·ì—ì„œ ETF PDF ë¡œë“œ ì™„ë£Œ: {len(df_pdf)}ê±´")
        #         return df_pdf
        #     except Exception as e:
        #         print(f"âš ï¸ ë¡œì»¬ CSV ë¡œë“œ ì‹¤íŒ¨ ({e}), Supabaseì—ì„œ ì§ì ‘ ë¡œë“œí•©ë‹ˆë‹¤.")

        all_data = []
        limit = 1000
        offset = 0
        
        print("â³ Supabase ETF PDF ë°ì´í„° ë¡œë“œ ì¤‘...", end='', flush=True)
        
        while True:
            # í˜ì´ì§€ë„¤ì´ì…˜: offsetë¶€í„° limitë§Œí¼ ê°€ì ¸ì˜¤ê¸°
            response = supabase.table("ETF_PDF").select("*").range(offset, offset + limit - 1).execute()
            
            if not response.data:
                break
                
            all_data.extend(response.data)
            
            # ê°€ì ¸ì˜¨ ë°ì´í„°ê°€ limitë³´ë‹¤ ì ìœ¼ë©´ ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ë‹¤ëŠ” ëœ»
            if len(response.data) < limit:
                break
            
            offset += limit
            print(".", end='', flush=True)

        print(f"\nâœ… Supabase ETF PDF ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(all_data)}ê±´")

        if not all_data:
            print("ğŸš¨ Supabaseì˜ 'ETF_PDF' í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        df_pdf = pd.DataFrame(all_data)
        
        # ì»¬ëŸ¼ëª… í†µì¼ (DB ì»¬ëŸ¼ëª… -> ë¡œì§ìš© ì»¬ëŸ¼ëª…)
        column_mapping = {
            'etf_code': 'ETFì¢…ëª©ì½”ë“œ',
            'etf_name': 'ETFì¢…ëª©ëª…',
            'holdings_code': 'êµ¬ì„±ì¢…ëª©ì½”ë“œ',
            'holdings_name': 'êµ¬ì„±ì¢…ëª©ëª…',
            'holdings_weight': 'êµ¬ì„±ë¹„ì¤‘(%)'
        }
        
        # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ë³€ê²½
        existing_mapping = {k: v for k, v in column_mapping.items() if k in df_pdf.columns}
        if existing_mapping:
            df_pdf.rename(columns=existing_mapping, inplace=True)

        # ì¶”ê°€ì ì¸ ì»¬ëŸ¼ëª… í˜¸í™˜ ì²˜ë¦¬ (ì‹œê°€ì´ì•¡ê¸°ì¤€êµ¬ì„±ë¹„ìœ¨ ë“±)
        if 'ì‹œê°€ì´ì•¡ê¸°ì¤€êµ¬ì„±ë¹„ìœ¨' in df_pdf.columns:
            df_pdf.rename(columns={'ì‹œê°€ì´ì•¡ê¸°ì¤€êµ¬ì„±ë¹„ìœ¨': 'êµ¬ì„±ë¹„ì¤‘(%)'}, inplace=True)
        
        if 'êµ¬ì„±ë¹„ì¤‘(%)' not in df_pdf.columns:
            print(f"âš ï¸ 'êµ¬ì„±ë¹„ì¤‘(%)' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì»¬ëŸ¼: {list(df_pdf.columns)})")

        df_pdf['êµ¬ì„±ë¹„ì¤‘(%)'] = pd.to_numeric(df_pdf['êµ¬ì„±ë¹„ì¤‘(%)'], errors='coerce').fillna(0)
        
        # ì¢…ëª©ì½”ë“œ í¬ë§·íŒ… (6ìë¦¬ ë¬¸ìì—´)
        if 'ETFì¢…ëª©ì½”ë“œ' in df_pdf.columns:
            df_pdf['ETFì¢…ëª©ì½”ë“œ'] = df_pdf['ETFì¢…ëª©ì½”ë“œ'].astype(str).str.zfill(6)
        if 'êµ¬ì„±ì¢…ëª©ì½”ë“œ' in df_pdf.columns:
            df_pdf['êµ¬ì„±ì¢…ëª©ì½”ë“œ'] = df_pdf['êµ¬ì„±ì¢…ëª©ì½”ë“œ'].astype(str).str.zfill(6)

        return df_pdf

    except Exception as e:
        print(f"ğŸš¨ Supabase ETF PDF ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        return None

def save_score_to_supabase(df, target_time=None):
    """
    ê³„ì‚°ëœ YG Score ê²°ê³¼ë¥¼ Supabase 'toss_yg_score_etf' í…Œì´ë¸”ì— ì €ì¥(Upsert)í•©ë‹ˆë‹¤.
    target_timeì´ ì œê³µë˜ë©´ í•´ë‹¹ ì‹œê°„ì„ updated_atìœ¼ë¡œ ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ í˜„ì¬ ì‹œê°„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    try:
        if df is None or df.empty:
            print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # 1. ì €ì¥í•  ë°ì´í„° ì¤€ë¹„ (ì»¬ëŸ¼ ë§¤í•‘)
        df_new = df.copy()
        df_new.rename(columns={
            'ETFì¢…ëª©ì½”ë“œ': 'etf_code',
            'ETFì¢…ëª©ëª…': 'etf_name',
            'YG_SCORE_í•©ê³„': 'total_score',
            'YG_SCORE_ì™¸êµ­ì¸': 'foreign_score',
            'YG_SCORE_ê¸°ê´€': 'institution_score',
            'ì¢…ëª©ìˆ˜': 'holdings_count'
        }, inplace=True)
        
        # 2. ì—…ë¡œë“œí•  ë°ì´í„° êµ¬ì„±
        # target_timeì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ í˜„ì¬ KST ì‹œê°„ ìƒì„±
        if target_time:
            current_time = target_time
        else:
            kst_now = datetime.utcnow() + timedelta(hours=9)
            current_time = kst_now.isoformat()
        
        upsert_cols = ['etf_code', 'etf_name', 'total_score', 'foreign_score', 'institution_score', 'holdings_count', 'updated_at']
        
        # updated_at ì¶”ê°€
        df_new['updated_at'] = current_time
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ì—¬ dict ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        data_to_upsert = df_new[upsert_cols].to_dict(orient='records')

        # 3. ë°ì´í„° ì €ì¥ (ì „ì²´ Upsert)
        # ë°ì´í„°ê°€ ë§ì„ ê²½ìš° Supabase ìš”ì²­ ì œí•œì— ê±¸ë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ 1000ê°œì”© ë¶„í•  ì²˜ë¦¬
        batch_size = 1000
        total_count = len(data_to_upsert)
        
        print(f"ğŸš€ ì´ {total_count}ê±´ ë°ì´í„° ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        for i in range(0, total_count, batch_size):
            batch = data_to_upsert[i:i+batch_size]
            # [ìˆ˜ì •] etf_codeì™€ updated_atì„ ëª¨ë‘ ê¸°ì¤€ìœ¼ë¡œ ì‚¼ì•„ ì´ë ¥ì´ ìŒ“ì´ë„ë¡ í•¨
            res = supabase.table("toss_yg_score_etf").upsert(batch, on_conflict="etf_code, updated_at").execute()
            print(f"   - {i} ~ {i+len(batch)}ê±´ ì €ì¥ ì™„ë£Œ")
            
        print(f"âœ… Supabase 'toss_yg_score_etf' í…Œì´ë¸” ì „ì²´ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {total_count}ê±´")

    except Exception as e:
        print(f"ğŸš¨ Supabase ì €ì¥ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")

def delete_old_scores():
    """
    toss_yg_score_etf ë° toss_yg_score_skt í…Œì´ë¸”ì—ì„œ ì˜¤ëŠ˜(KST ê¸°ì¤€) ì´ì „ì˜ ë°ì´í„°ë¥¼ ëª¨ë‘ ì‚­ì œí•©ë‹ˆë‹¤.
    ì¦‰, ì‹¤í–‰ì¼ ë‹¹ì¼ì˜ ë°ì´í„°ë§Œ ë‚¨ê¹ë‹ˆë‹¤.
    """
    try:
        # KST ê¸°ì¤€ ì˜¤ëŠ˜ ì‹œì‘ ì‹œê°„ ê³„ì‚°
        now_utc = datetime.utcnow()
        now_kst = now_utc + timedelta(hours=9)
        today_start_kst = now_kst.replace(hour=0, minute=0, second=0, microsecond=0)
        
        # ë¹„êµë¥¼ ìœ„í•´ UTCë¡œ ë³€í™˜ (updated_atì€ UTCë¡œ ì €ì¥ë¨)
        # [ìˆ˜ì •] KST ISO í¬ë§·ìœ¼ë¡œ ì €ì¥í•˜ë¯€ë¡œ, thresholdë„ KST ISO í¬ë§·ìœ¼ë¡œ ì„¤ì •
        threshold_str = today_start_kst.isoformat()

        # ì‚­ì œ ì¿¼ë¦¬ 1: toss_yg_score_etf í…Œì´ë¸” (updated_at < threshold)
        response = supabase.table("toss_yg_score_etf").delete().lt("updated_at", threshold_str).execute()
        
        deleted_count = len(response.data) if response.data else 0
        if deleted_count > 0:
            print(f"ğŸ§¹ ì§€ë‚œ Score ë°ì´í„° ì‚­ì œ ì™„ë£Œ: {deleted_count}ê±´ (ê¸°ì¤€: {today_start_kst.strftime('%Y-%m-%d')} KST ì´ì „)")

        # ì‚­ì œ ì¿¼ë¦¬ 2: toss_yg_score_stk í…Œì´ë¸” (collected_at < threshold)
        # collected_atì´ KST Timestampë¡œ ì €ì¥ë˜ë¯€ë¡œ ë™ì¼ ê¸°ì¤€ ì‚¬ìš©
        response_top = supabase.table("toss_yg_score_stk").delete().lt("collected_at", threshold_str).execute()
        
        deleted_count_top = len(response_top.data) if response_top.data else 0
        if deleted_count_top > 0:
            print(f"ğŸ§¹ ì§€ë‚œ Top100 ë°ì´í„° ì‚­ì œ ì™„ë£Œ: {deleted_count_top}ê±´")
            
    except Exception as e:
        print(f"ğŸš¨ ì§€ë‚œ ë°ì´í„° ì‚­ì œ ì˜¤ë¥˜: {e}")
