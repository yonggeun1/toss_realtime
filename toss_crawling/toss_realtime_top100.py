import time
from datetime import datetime, timedelta
import re
import sys
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# Supabase í´ë¼ì´ì–¸íŠ¸ ì„í¬íŠ¸
try:
    from toss_crawling.supabase_client import supabase, delete_old_scores, load_etf_pdf_from_supabase
    from toss_crawling.toss_realtime_score import calculate_yg_score
except ImportError:
    # ë¡œì»¬ ì‹¤í–‰ ì‹œ ê²½ë¡œ ë¬¸ì œ ëŒ€ë¹„
    import os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from supabase_client import supabase, delete_old_scores, load_etf_pdf_from_supabase
    from toss_realtime_score import calculate_yg_score

def parse_amount(amount_str):
    if not amount_str:
        return 0
    try:
        # "-", "ì›", "ìˆœë§¤ìˆ˜/ë„" ë“± ë¶ˆí•„ìš”í•œ ë¬¸ìì—´ ì œê±° ë° ì •ì œ
        amount_str = amount_str.replace("ìˆœë§¤ìˆ˜", "").replace("ìˆœë§¤ë„", "").replace(",", "").replace(" ", "").replace("-", "").replace("ì›", "")
        total_amount = 0.0
        
        # ì¡° ë‹¨ìœ„ ì²˜ë¦¬ (1ì¡° = 10000ì–µ)
        if "ì¡°" in amount_str:
            parts = amount_str.split("ì¡°")
            try:
                if parts[0].strip():
                    jo_part = float(parts[0])
                    total_amount += jo_part * 10000
            except: pass
            amount_str = parts[1] if len(parts) > 1 else ""
            
        # ì–µ ë‹¨ìœ„ ì²˜ë¦¬
        if "ì–µ" in amount_str:
            parts = amount_str.split("ì–µ")
            try:
                if parts[0].strip():
                    uk_part = float(parts[0])
                    total_amount += uk_part
            except: pass
            amount_str = parts[1] if len(parts) > 1 else ""
            
        # ë§Œ ë‹¨ìœ„ ì²˜ë¦¬ (1ë§Œ = 0.0001ì–µ)
        if "ë§Œ" in amount_str:
            parts = amount_str.split("ë§Œ")
            try:
                if parts[0].strip():
                    man_part = float(parts[0])
                    total_amount += man_part / 10000
            except: pass
            
        return round(total_amount, 4)
    except:
        return 0

def parse_date(date_str):
    """
    í† ìŠ¤ì¦ê¶Œ ë‚ ì§œ í˜•ì‹(ì˜¤ëŠ˜, ì–´ì œ, 1ì›” 30ì¼ ë“±)ì„ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    """
    # KST ê¸°ì¤€ ì‹œê°„ ì‚¬ìš©
    kst_now = datetime.utcnow() + timedelta(hours=9)
    today_str = kst_now.strftime('%Y-%m-%d')
    current_year = kst_now.year
    
    if not date_str:
        return today_str

    if "ì˜¤ëŠ˜" in date_str:
        return today_str
    
    if "ì–´ì œ" in date_str:
        yesterday = kst_now - timedelta(days=1)
        return yesterday.strftime('%Y-%m-%d')
    
    # 1ì›” 30ì¼ í¬ë§·
    match = re.search(r'(\d+)ì›”\s*(\d+)ì¼', date_str)
    if match:
        month = int(match.group(1))
        day = int(match.group(2))
        return f"{current_year}-{month:02d}-{day:02d}"

    # ì´ë¯¸ YYYY-MM-DD í˜•ì‹ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if re.match(r'\d{4}-\d{2}-\d{2}', date_str):
        return date_str
        
    return today_str

def get_toss_ranking(ranking_type="buy"):
    # ranking_type: 'buy' (ìˆœë§¤ìˆ˜) or 'sell' (ìˆœë§¤ë„)
    ranking_name = "ìˆœë§¤ìˆ˜" if ranking_type == "buy" else "ìˆœë§¤ë„"
    
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1920,3000")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36")

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
    url = f"https://www.tossinvest.com/?ranking-type=domestic_investor_trend&ranking={ranking_type}"
    
    all_data = []
    
    try:
        print(f"ğŸš€ [{ranking_type}] Connecting to: {url}")
        driver.get(url)
        wait = WebDriverWait(driver, 15)
        
        # ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œ ë¡œë”© ëŒ€ê¸°
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "a[href*='/stocks/']")))
        time.sleep(5) 
        
        # ğŸ“œ ìŠ¤í¬ë¡¤ ë‹¤ìš´
        last_height = driver.execute_script("return document.body.scrollHeight")
        while True:
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)
            new_height = driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                break
            last_height = new_height
        print(f"ğŸ“œ [{ranking_type}] Page scroll completed")
        
        # ğŸ•’ ê¸°ì¤€ ì‹œê°„ ì¶”ì¶œ (íˆ¬ììë³„)
        base_times = {}
        # ì™¸êµ­ì¸, ê¸°ê´€ XPath ë§¤í•‘
        time_xpaths = {
            "ì™¸êµ­ì¸": "/html/body/div[1]/div[2]/div/div[1]/main/div/div/div[2]/div[5]/section/div[3]/section[1]/hgroup/div/div/span",
            "ê¸°ê´€": "/html/body/div[1]/div[2]/div/div[1]/main/div/div/div[2]/div[5]/section/div[3]/section[2]/hgroup/div/div/span"
        }
        
        default_time = time.strftime('%Y-%m-%d %H:%M:%S')

        for inv_type, xpath in time_xpaths.items():
            try:
                el = driver.find_element(By.XPATH, xpath)
                base_times[inv_type] = el.text.strip()
                print(f"ğŸ•’ [{ranking_type}] {inv_type} Base Time: {base_times[inv_type]}")
            except:
                base_times[inv_type] = default_time
                print(f"âš ï¸ [{ranking_type}] {inv_type} Base Time extraction failed")

        # ì „ì²´ ì¢…ëª© ì•„ì´í…œ ìˆ˜ì§‘
        items = driver.find_elements(By.CSS_SELECTOR, "a[href*='/stocks/']")
        print(f"ğŸ“¦ [{ranking_type}] Found {len(items)} raw items")

        current_group_idx = 0
        groups = ["ì™¸êµ­ì¸", "ê¸°ê´€", "ê°œì¸", "ê¸°íƒ€"]
        group_counts = {"ì™¸êµ­ì¸": 0, "ê¸°ê´€": 0}

        # KST ê¸°ì¤€ ì˜¤ëŠ˜ ë‚ ì§œ ê³„ì‚° (ë£¨í”„ ë°–ì—ì„œ í•œ ë²ˆ ê³„ì‚°)
        kst_now = datetime.utcnow() + timedelta(hours=9)
        today_str = kst_now.strftime('%Y-%m-%d')
        # [ìˆ˜ì •] ìˆ˜ì§‘ ì‹œê°„(collected_at)ì„ KST ì „ì²´ íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ì„¤ì • (ì´ë ¥ ëˆ„ì ìš©)
        collected_at_kst = kst_now.isoformat()

        for idx, item in enumerate(items):
            try:
                raw_text = item.text
                if not raw_text: continue
                
                text_lines = [line.strip() for line in raw_text.split('\n') if line.strip()]
                
                if len(text_lines) >= 2:
                    rank = text_lines[0]
                    name = text_lines[1]
                    
                    # ê·¸ë£¹ ì¸ë±ìŠ¤ ì¦ê°€ ë¡œì§ (Rank '1'ì„ ë§Œë‚¬ì„ ë•Œ ë‹¤ìŒ ê·¸ë£¹ìœ¼ë¡œ ì´ë™)
                    # ë‹¨, ë„ˆë¬´ ë¹¨ë¦¬ ë°”ë€Œì§€ ì•Šë„ë¡ ìµœì†Œ ê°œìˆ˜(ì˜ˆ: 90ê°œ) ì´í›„ì—ë§Œ ì²´í¬
                    if rank == '1' and idx > 10: 
                         if group_counts.get(groups[current_group_idx], 0) >= 90:
                            current_group_idx += 1
                            print(f"ğŸ“Œ [{ranking_type}] Switched to next group: {groups[current_group_idx]} at index {idx}")
                    
                    group_name = groups[current_group_idx] if current_group_idx < len(groups) else "Unknown"
                    
                    if group_name not in ["ì™¸êµ­ì¸", "ê¸°ê´€"]:
                        continue

                    # ì´ë¯¸ í•´ë‹¹ ê·¸ë£¹ 100ê°œë¥¼ ì±„ì› ë‹¤ë©´ í•´ë‹¹ ì•„ì´í…œì€ ìŠ¤í‚µ
                    if group_counts[group_name] >= 100:
                        continue

                    # ğŸ” ì¢…ëª©ì½”ë“œ ì¶”ì¶œ
                    try:
                        href = item.get_attribute("href")
                        if "/stocks/A" in href:
                            stock_code = href.split("/stocks/A")[1].split("/")[0]
                        else:
                            stock_code = ""
                    except:
                        stock_code = ""

                    # ì´ë¦„ ë³´ì • ë¡œì§
                    if re.match(r'^[0-9,.\-+\s%]+(ì›)?$', name):
                        if len(text_lines) > 2:
                            name = text_lines[2]
                    
                    # ê¸ˆì•¡ ì •ë³´ íŒŒì‹±
                    amount_str = ""
                    is_yesterday = False
                    for line in text_lines:
                        if "ì–´ì œ" in line:
                            is_yesterday = True
                        if any(unit in line for unit in ["ì¡°", "ì–µ", "ë§Œ"]):
                            amount_str = line.strip()
                    
                    # "ì–´ì œ" ë°ì´í„°ì¸ ê²½ìš° ê¸ˆì•¡ì„ 0ìœ¼ë¡œ ê°•ì œ ì„¤ì •
                    if is_yesterday:
                        amount_val = 0.0
                        print(f"âš ï¸ [{ranking_type}] {group_name} - {name} ({stock_code}) ë°ì´í„°ê°€ 'ì–´ì œ' ê²ƒì´ë¯€ë¡œ 0ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
                    else:
                        amount_val = parse_amount(amount_str)
                    
                    # ë°ì´í„° ì €ì¥ìš© dict ìƒì„±
                    all_data.append({
                        "investor": group_name,
                        "stock_name": name,
                        "stock_code": stock_code,
                        "amount": amount_val,
                        "ranking_type": ranking_type,
                        "collected_at": collected_at_kst
                    })
                    group_counts[group_name] += 1
            except Exception as e:
                continue

        print(f"ğŸ“Š [{ranking_type}] Final Counts -> å¤–: {group_counts.get('ì™¸êµ­ì¸', 0)}, æ©Ÿ: {group_counts.get('ê¸°ê´€', 0)}")

        # ê²°ê³¼ ì €ì¥ (Supabase)
        if all_data:
            # ì¤‘ë³µ ì œê±° (investor, stock_code, stock_name ì¡°í•© ê¸°ì¤€)
            unique_map = {}
            for item in all_data:
                # stock_codeê°€ ì—†ëŠ” ê²½ìš° nameì„ ì‚¬ìš©í•˜ì—¬ ê³ ìœ ì„± ìœ ì§€
                key = (item["investor"], item["stock_code"], item["stock_name"], item["ranking_type"])
                unique_map[key] = item
            all_data = list(unique_map.values())

            try:
                # Supabaseì— ë°ì´í„° ì‚½ì… (upsert ì‚¬ìš©)
                response = supabase.table("toss_realtime_top100").upsert(
                    all_data, 
                    on_conflict="investor, stock_code, ranking_type, collected_at"
                ).execute()
                print(f"\nğŸ‰ [{ranking_type}] Supabase Save Complete (Total {len(all_data)} items)")
                
            except Exception as e:
                print(f"âŒ [{ranking_type}] Supabase Save Error: {e}")
                
        else:
            print(f"âŒ [{ranking_type}] No collected data.")
        
    except Exception as e:
        print(f"âŒ [{ranking_name}] ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        driver.quit()

if __name__ == "__main__":
    
    # ì¸ì í™•ì¸
    run_once = "--once" in sys.argv
    is_morning = "--session morning" in sys.argv
    is_afternoon = "--session afternoon" in sys.argv

    # PDF ë°ì´í„° ìµœì´ˆ 1íšŒ ë¡œë“œ
    print("Loading ETF PDF data...")
    cached_pdf_data = load_etf_pdf_from_supabase()

    # ğŸ§¹ [ë³€ê²½] ì˜¤ëŠ˜ ì´ì „ ë°ì´í„° ì‚­ì œëŠ” ì‹œì‘ ì‹œ 1íšŒë§Œ ìˆ˜í–‰ (ì˜¤ì „ ì„¸ì…˜ ë˜ëŠ” ë‹¨ë… ì‹¤í–‰ ì‹œì—ë§Œ)
    if not is_afternoon:
        print("ğŸ§¹ Cleaning up old data (older than today) before starting loop...")
        delete_old_scores()

    while True:
        # ğŸ•’ ì„œë²„ ì‹œê°„(UTC)ì— 9ì‹œê°„ì„ ë”í•´ í•œêµ­ ì‹œê°„(KST) êµ¬í•˜ê¸°
        now = datetime.utcnow() + timedelta(hours=9)
        
        # ì¢…ë£Œ ì‹œê°„ ì„¤ì •
        # ê¸°ë³¸ì€ 15:30 ì¢…ë£Œ
        end_hour, end_minute = 15, 30
        
        # ì˜¤ì „ ì„¸ì…˜ì¸ ê²½ìš° 12:00 ì¢…ë£Œ
        if is_morning:
            end_hour, end_minute = 12, 0
            
        # ì¢…ë£Œ ì¡°ê±´ ì²´í¬ (KST ê¸°ì¤€)
        if not run_once and (now.hour > end_hour or (now.hour == end_hour and now.minute >= end_minute)):
            print(f"ğŸ•’ í˜„ì¬ ì‹œê°„(KST) {now.strftime('%H:%M:%S')} - ì„¸ì…˜ ì¢…ë£Œ ì‹œê°„({end_hour:02d}:{end_minute:02d})ì´ ë˜ì–´ ìˆ˜ì§‘ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        start_time = time.time()
        
        # [ì œê±°ë¨] delete_old_scores() ì—¬ê¸°ì„œëŠ” í˜¸ì¶œí•˜ì§€ ì•ŠìŒ (ë£¨í”„ ì§„ì… ì „ 1íšŒë§Œ í˜¸ì¶œ)
        
        print(f"=== í† ìŠ¤ì¦ê¶Œ ìˆ˜ê¸‰ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (ì‹œì‘ ì‹œê° KST: {now.strftime('%H:%M:%S')}) ===")
        
        try:
            get_toss_ranking("buy")  # ìˆœë§¤ìˆ˜
            print("\n" + "="*30 + "\n")
            get_toss_ranking("sell") # ìˆœë§¤ë„
            
            # ğŸš€ í¬ë¡¤ë§ ì™„ë£Œ í›„ ì ìˆ˜ ê³„ì‚° ë° ì—…ë°ì´íŠ¸ ì‹¤í–‰
            print("\nğŸ“Š YG Score ê³„ì‚° ë° score í…Œì´ë¸” ì—…ë°ì´íŠ¸ ì‹œì‘...")
            try:
                calculate_yg_score(df_pdf=cached_pdf_data)
                print("âœ… YG Score ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ YG Score ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                
        except Exception as e:
            print(f"âŒ ë©”ì¸ ë£¨í”„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        print("=== ì´ë²ˆ í„´ ìˆ˜ì§‘ ì™„ë£Œ ===")
        
        if run_once:
            print("ğŸš€ 1íšŒ ì‹¤í–‰ ëª¨ë“œ ì™„ë£Œ. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        
        elapsed_time = time.time() - start_time
        wait_time = 60 - elapsed_time
        
        if wait_time > 0:
            print(f"â³ ë‹¤ìŒ ìˆ˜ì§‘ê¹Œì§€ {wait_time:.1f}ì´ˆ ëŒ€ê¸°...")
            time.sleep(wait_time)
        else:
            print("â³ ëŒ€ê¸° ì—†ì´ ë°”ë¡œ ë‹¤ìŒ ìˆ˜ì§‘ ì‹œì‘")
